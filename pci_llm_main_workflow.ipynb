{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPbGLeKNz0RliV38Gv58uFU"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## **Current Experiment: Revised Experiment #1 (Aggregated Sparse-Synthetic Data)**\n","\n","This run of the notebook focuses on **Experiment #1 (Revised)**. In this experiment, the LLM's Stage 1 is trained on data that is:\n","* Derived from **sparse individual synthetic pavement sections** (simulating real-world inspection infrequency).\n","* **Aggregated by ClimateZone, SurfaceType, and Age** to create dense, average degradation curves.\n","\n","This approach aims to teach the LLM general, continuous degradation patterns from averaged data, which it will later adapt to specific individual sections in Stage 2.\n","\n","---\n","\n","### **Workflow Sections:**\n","\n","1.  **Colab Session Setup:** Initial environment setup (Drive, GitHub, Libraries).\n","2.  **Data Generation & Preparation:** Functions to create and preprocess synthetic data.\n","3.  **Data Preprocessing & DataLoader Setup:** Preparing data for PyTorch.\n","4.  **Model Definition & Initialization:** Defining and instantiating the LLM architecture.\n","5.  **Stage 1 Training Loop:** The core learning phase.\n","6.  **Model Saving & Evaluation:** Saving progress and checking performance (future steps)."],"metadata":{"id":"23vASuL-dcBC"}},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"szYtYLi7rDhS","executionInfo":{"status":"ok","timestamp":1749492700973,"user_tz":240,"elapsed":29760,"user":{"displayName":"Anthony Meyer","userId":"00256956543810889303"}},"outputId":"37d6af22-98a5-4447-f6e3-d5173a175a87"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounting Google Drive...\n","Mounted at /content/drive\n","Google Drive mounted.\n"]}],"source":["# Cell 1.1: Mount Google Drive (Optional but Recommended for Larger Files)\n","import os # Make sure os is imported\n","\n","# Check if Drive is already mounted\n","if not os.path.exists('/content/drive'):\n","    from google.colab import drive\n","    print(\"Mounting Google Drive...\")\n","    drive.mount('/content/drive')\n","    print(\"Google Drive mounted.\")\n","else:\n","    print(\"Google Drive is already mounted.\")\n"]},{"cell_type":"code","source":["# Cell 1.2: Set Up GitHub Credentials & Clone/Update Repository (Enhanced Robustness)\n","import os\n","\n","# --- 1. Set Git User Identity (Persists for the session) ---\n","!git config --global user.email \"anthony@icatalystinc.com\"\n","!git config --global user.name \"Anthony Meyer\"\n","print(\"Git user identity configured.\")\n","\n","# --- 2. Set GitHub Personal Access Token (PAT) as an environment variable ---\n","# IMPORTANT SECURITY WARNING:\n","# Direct embedding of PATs in notebooks is NOT secure for shared or public notebooks.\n","# For production or shared environments, use Colab's \"Secrets\" feature (key icon on left sidebar).\n","# For personal projects, you can use this for convenience.\n","# Replace \"your_pat_here\" with your actual PAT.\n","os.environ[\"GITHUB_PAT\"] = \"ghp_qAlrEycrxTF6FUn7XaYSKOR0LVZPLb24HPme\"\n","print(\"GITHUB_PAT environment variable set.\")\n","\n","# --- 3. Define Repository Info ---\n","# Construct the URL with PAT for cloning (only needed for private repos)\n","repo_url_with_pat = f\"https://{os.environ['GITHUB_PAT']}@github.com/iCatalyst-D3M/pci-forecasting.git\"\n","repo_name = \"pci-forecasting\" # Your repository's folder name\n","\n","# --- 4. Navigate to /content and Robustly Clone/Update Repository ---\n","# All clones typically go into /content in Colab\n","%cd /content\n","\n","# Proactive check and cleanup:\n","# If the directory exists but is not a valid Git repo, or if it looks like a nested one, remove it.\n","if os.path.exists(repo_name):\n","    # Check if .git subdirectory (indicates a git repo) or if a nested repo is found\n","    if not os.path.exists(os.path.join(repo_name, '.git')) or os.path.exists(os.path.join(repo_name, repo_name)):\n","        print(f\"Detected problematic or non-Git '{repo_name}' directory. Removing it to re-clone cleanly.\")\n","        !rm -rf {repo_name}\n","        print(\"Removed existing problematic directory.\")\n","    else:\n","        print(f\"'{repo_name}' directory exists and appears to be a valid Git repo. Proceeding to pull.\")\n","\n","# Now, perform the clone or pull (after potential cleanup)\n","if not os.path.exists(repo_name):\n","    print(f\"\\nCloning {repo_name}...\")\n","    !git clone {repo_url_with_pat}\n","    print(\"Repository cloned.\")\n","else:\n","    # This block is executed if repo_name exists AND is likely valid (not problematic)\n","    print(f\"\\nRepository {repo_name} exists. Pulling latest changes...\")\n","    %cd {repo_name}\n","    !git pull\n","    %cd ..\n","    print(\"Repository updated.\")\n","\n","# --- 5. Navigate into your Repository Directory for all subsequent work ---\n","# This is the final step to ensure your notebook is operating from your repo's root\n","%cd {repo_name}\n","\n","# Verify current working directory and list contents\n","print(f\"\\nCurrently in: {os.getcwd()}\")\n","!ls"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KL-gjWw-KiA5","executionInfo":{"status":"ok","timestamp":1749497844342,"user_tz":240,"elapsed":764,"user":{"displayName":"Anthony Meyer","userId":"00256956543810889303"}},"outputId":"d44b4561-2853-4c9a-fff1-9352d918e7bd"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Git user identity configured.\n","GITHUB_PAT environment variable set.\n","/content\n","Currently in:\n","'pci-forecasting' directory exists and appears to be a valid Git repo. Proceeding to pull.\n","\n","Repository pci-forecasting exists. Pulling latest changes...\n","/content/pci-forecasting\n","Already up to date.\n","/content\n","Repository updated.\n","/content/pci-forecasting\n","\n","Currently in: /content/pci-forecasting\n","aggregated_synthetic_pci_data.csv  predict_all_2.csv\n","pci_forecasting.ipynb\t\t   synthetic_pci_data.csv\n"]}]},{"cell_type":"code","source":["# Cell 1.3: Create src/ directory and make it a Python package (Run this once per session)\n","\n","import os\n","\n","# Define the path for your source directory\n","src_dir = 'src'\n","init_file = os.path.join(src_dir, '__init__.py')\n","\n","# Check if the src directory exists, if not, create it\n","if not os.path.exists(src_dir):\n","    os.makedirs(src_dir)\n","    print(f\"Created '{src_dir}' directory.\")\n","else:\n","    print(f\"'{src_dir}' directory already exists.\")\n","\n","# Ensure __init__.py exists to make 'src' a Python package\n","if not os.path.exists(init_file):\n","    with open(init_file, 'w') as f:\n","        f.write('') # Write an empty file\n","    print(f\"Created empty '{init_file}' to make 'src' a package.\")\n","else:\n","    print(f\"'{init_file}' already exists.\")\n","\n","print(\"File structure setup for 'src/' complete locally.\")\n","print(\"\\nNEXT STEPS: Manually create/paste your code into src/dataset.py and src/models.py using the Colab file browser, then run the next cell.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tlY5tfsZe5SR","executionInfo":{"status":"ok","timestamp":1749502642348,"user_tz":240,"elapsed":18,"user":{"displayName":"Anthony Meyer","userId":"00256956543810889303"}},"outputId":"95271102-7d05-477d-e906-302ef7427354"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["Created 'src' directory.\n","Created empty 'src/__init__.py' to make 'src' a package.\n","File structure setup for 'src/' complete locally.\n","\n","NEXT STEPS: Manually create/paste your code into src/dataset.py and src/models.py using the Colab file browser, then run the next cell.\n"]}]},{"cell_type":"code","source":["# Cell 1.4 Committing files to GitHub\n","\n","import os\n","\n","# --- 1. Define Notebook Name and Paths ---\n","# Replace 'pci_llm_main_workflow.ipynb' with the exact name you saved your notebook as in Google Drive.\n","notebook_name = \"pci_llm_main_workflow.ipynb\"\n","\n","# Assuming your notebook is in the default 'Colab Notebooks' folder in your Drive.\n","# If you saved it elsewhere in Drive, adjust this path.\n","notebook_path_in_drive = f\"/content/drive/MyDrive/Colab Notebooks/{notebook_name}\"\n","\n","# Your current working directory is the root of your cloned repo (e.g., /content/pci-forecasting/)\n","# We will copy the notebook to this directory.\n","destination_path_in_repo = \".\" # '.' means current directory\n","\n","print(f\"Attempting to copy notebook from: {notebook_path_in_drive}\")\n","print(f\"To current repo directory: {os.getcwd()}\")\n","\n","\n","# --- 2. Copy the Notebook from Drive into your Cloned Repository ---\n","# Use !cp to copy the file. -f means force overwrite if it exists.\n","!cp -f \"{notebook_path_in_drive}\" \"{destination_path_in_repo}\"\n","print(f\"\\nNotebook '{notebook_name}' copied into the local repository folder.\")\n","\n","# Verify it's in the current directory now\n","!ls # You should now see your notebook_name.ipynb listed here\n","\n","\n","# --- 3. Stage, Commit, and Push the Notebook to GitHub ---\n","print(\"\\n--- Committing Notebook to GitHub ---\")\n","\n","# Stage the notebook file for commit\n","!git add {notebook_name}\n","\n","# Stage any other pending changes (e.g., if you just created src/ and its __init__.py)\n","# You might have already added these in Cell 2.4, but it's safe to add again if unsure.\n","!git add src/ # Adds src/ and its contents, including __init__.py\n","\n","# Commit your changes with a descriptive message\n","!git commit -m \"Add main LLM workflow notebook to repo; ensure src/ is tracked\"\n","\n","# Push changes to GitHub (Colab might prompt for credentials if not configured with PAT)\n","# Ensure GITHUB_PAT environment variable is set from Cell 1.2\n","!git push\n","\n","print(f\"\\nNotebook '{notebook_name}' and other changes pushed to GitHub!\")\n","print(\"You can now verify this in your GitHub repository.\")"],"metadata":{"id":"WsdWG7jXhkBK"},"execution_count":null,"outputs":[]}]}